# ğŸ“˜ Employee Wellbeing & Burnout Early Warning System

### ML-Powered Burnout Prediction + RAG-Enhanced AI Advisor

*A Streamlit application for predicting burnout risk, explaining drivers, and providing HR-policy-aware AI guidance.*

---

# ğŸ“‚ Table of Contents

* [ğŸŒŸ Project Overview](#-project-overview)
* [ğŸ§° Requirements](#-requirements)
* [ğŸ’» Installation Guide](#-installation-guide)

  * [1. Install Python (Windows & macOS)](#1-install-python-windows--macos)
  * [2. Clone This Repository](#3-clone-this-repository)
  * [3. Create and Activate Virtual Environment](#4-create-and-activate-virtual-environment)
  * [4. Install Python Dependencies](#5-install-python-dependencies)
* [ğŸ¤– Installing & Running Ollama (Local LLM Engine)](#-installing--running-ollama-local-llm-engine)

  * [Install Ollama](#install-ollama)
  * [Download Required Model](#download-required-model)
  * [Test the Model](#test-the-model)
* [ğŸš€ Run the Application](#-run-the-application)
* [ğŸ“¦ Project Structure](#-project-structure)
* [ğŸ›  Troubleshooting](#-troubleshooting)
* [ğŸ“œ License](#-license)

---

# ğŸŒŸ Project Overview

This project predicts employee burnout using machine learning and provides:

* **Burnout risk scoring (0â€“100%)**
* **Risk classification: Low / Medium / High**
* **Explainability**: Top drivers (workload, stress, support, recognition, sleep, job satisfaction)
* **Individual analysis dashboard**
* **RAG-powered AI Advisor** with:

  * Action Playbooks
  * Context-aware coaching chat
  * Notes for managers
  * HR-policy-driven recommendations
* **Department-level heatmaps & trend views**

The system runs 100% locally using **Ollama** for AI â€” no cloud LLM needed.

---

# ğŸ§° Requirements

âœ” Windows 10/11 or macOS
âœ” Python **3.10 or newer**
âœ” Git
âœ” Ollama (for running local LLMs)
âœ” Minimum specs:

* 8 GB RAM (16 GB recommended)
* 10 GB free disk space

---

# ğŸ’» Installation Guide

## 1. Install Python (Windows & macOS)

### **Windows**

Download Python from:
ğŸ”— [https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)

During installation, check:

â˜‘ **Add Python to PATH**
â˜‘ **Install pip**

Verify installation:

```bash
python --version
pip --version
```

### **macOS**

Install via Homebrew:

```bash
brew install python
```

Verify:

```bash
python3 --version
pip3 --version
```

---

## 4. Create and Activate Virtual Environment

### Windows

```bash
python -m venv .venv
.venv\Scripts\activate
```

### macOS

```bash
python3 -m venv .venv
source .venv/bin/activate
```

---

## 5. Install Python Dependencies

```
pip install -r requirements.txt
```

---

# ğŸ¤– Installing & Running Ollama (Local LLM Engine)

## Install Ollama

### Windows:

Download installer:
[https://ollama.com/download/windows](https://ollama.com/download/windows)

### macOS:

```bash
brew install ollama
```

or download DMG:
[https://ollama.com/download/mac](https://ollama.com/download/mac)

Verify installation:

```bash
ollama --version
```

---

## Download Required Model

This app works best with **LLaMA 3.1 8B** or **Mistral 7B**.

Example (recommended):

```bash
ollama pull llama3.1:8b
```

Or:

```bash
ollama pull mistral:7b
```

---

## Test the Model

```bash
ollama run llama3.1:8b "Hello"
```

If you see a response â†’ you're good!

---

# ğŸš€ Run the Application

Inside your virtual environment, run:

```bash
streamlit run app.py
```

The app opens at:

ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

You're ready to explore:

* Dashboard
* Predictions
* Individual Analysis
* AI Advisor
* HR Policy Assistant

---

# ğŸ“¦ Project Structure

```
â”œâ”€â”€ app.py                    # Main Streamlit Application
â”œâ”€â”€ data_generation.py        # Synthetic/real data generation module
â”œâ”€â”€ features.py               # Feature engineering & scoring
â”œâ”€â”€ model_training.py         # ML model training pipeline
â”œâ”€â”€ rag_engine.py             # HR Policy RAG Engine
â”œâ”€â”€ llm_integration.py        # Ollama / OpenAI LLM wrapper
â”œâ”€â”€ config.py                 # Configuration and model settings
â”œâ”€â”€ policies/                 # HR policy text files for RAG
â”œâ”€â”€ data/                     # Training and prediction datasets
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file!
```

---

# ğŸ›  Troubleshooting

### âŒ **Ollama model not found**

```bash
ollama pull llama3.1:8b
```

### âŒ **Streamlit cannot find rerun()**

You installed an older version. Update:

```bash
pip install --upgrade streamlit
```

### âŒ **Python deps failing on Windows**

Update pip:

```bash
python -m pip install --upgrade pip
```

### âŒ **App shows blank page**

Check the terminal running Streamlit â€” look for missing imports or syntax errors.

### âŒ **No CUDA / GPU**

Ollama still works but slower. CPU mode is automatic.

---

# ğŸ“œ License

MIT License â€” free to modify, deploy, and customize.

---
